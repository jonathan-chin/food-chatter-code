{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d9d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: pacman\n",
      "\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m19764\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m49\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (28): url, published, content, lang, domain_url, parent_url, post_type, ...\n",
      "\u001b[32mdbl\u001b[39m (19): porn_level, fluency_level, sentiment, article_extended_attributes....\n",
      "\u001b[33mlgl\u001b[39m  (2): title, noise_category\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m16279\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m49\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (29): url, published, title, content, lang, domain_url, parent_url, post...\n",
      "\u001b[32mdbl\u001b[39m (19): porn_level, fluency_level, sentiment, article_extended_attributes....\n",
      "\u001b[33mlgl\u001b[39m  (1): noise_category\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m14642\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m49\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (29): url, published, content, lang, domain_url, parent_url, post_type, ...\n",
      "\u001b[32mdbl\u001b[39m (19): porn_level, fluency_level, sentiment, article_extended_attributes....\n",
      "\u001b[33mlgl\u001b[39m  (1): title\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m18355\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m49\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (28): url, published, content, lang, domain_url, parent_url, post_type, ...\n",
      "\u001b[32mdbl\u001b[39m (19): porn_level, fluency_level, sentiment, article_extended_attributes....\n",
      "\u001b[33mlgl\u001b[39m  (2): title, noise_category\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m1930\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m49\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (30): url, published, title, content, lang, domain_url, parent_url, post...\n",
      "\u001b[32mdbl\u001b[39m (19): porn_level, fluency_level, sentiment, article_extended_attributes....\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "Warning message:\n",
      "“One or more parsing issues, see `problems()` for details”\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m452\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m1\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (1): keyword\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "# to run a block of code, click on the cell and press control + enter\n",
    "# a block of code is still running if there's an asterisk to the left\n",
    "# run this block fo code JUST ONCE\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "\n",
    "# load and optionally install required packages\n",
    "if (!require('pacman')) install.packages('pacman')\n",
    "pacman::p_load(\n",
    "    dplyr,\n",
    "    readr,\n",
    "    scales,\n",
    "    stringr,\n",
    "    qdapRegex\n",
    ")\n",
    "\n",
    "# initial read in of all data\n",
    "csv_files <- list.files(path='./data/raw/talkwalker', full.names = T, pattern = 'FoodQuality*')\n",
    "data_groups <- lapply(csv_files, read_csv)\n",
    "data <- do.call(rbind, data_groups)\n",
    "\n",
    "# grab only columns we want and rekey some of them for convenience\n",
    "data.preprocessed <- data %>%\n",
    "    select(\n",
    "        # post data\n",
    "        content,\n",
    "        domain_url,\n",
    "        engagement,\n",
    "        fluency_level,\n",
    "        images.url,\n",
    "        lang,\n",
    "        matched_profile,\n",
    "        noise_category,\n",
    "        parent_url,\n",
    "        porn_level,\n",
    "        post_type,\n",
    "        published,\n",
    "        reach,\n",
    "        sentiment,\n",
    "        tags_internal,\n",
    "        title,\n",
    "        url,\n",
    "        url_views = article_extended_attributes.url_views,\n",
    "        videos.url,\n",
    "        word_count,\n",
    "        username = extra_author_attributes.short_name,\n",
    "        \n",
    "        # social media data\n",
    "        facebook_followers = source_extended_attributes.facebook_followers,\n",
    "        facebook_likes = article_extended_attributes.facebook_likes,\n",
    "        facebook_shares = article_extended_attributes.facebook_shares,\n",
    "        twitter_followers = source_extended_attributes.twitter_followers,\n",
    "        twitter_likes = article_extended_attributes.twitter_likes,\n",
    "        twitter_retweets = article_extended_attributes.twitter_retweets,\n",
    "        twitter_shares = article_extended_attributes.twitter_shares,\n",
    "        instagram_followers = source_extended_attributes.instagram_followers,\n",
    "        instagram_likes = article_extended_attributes.instagram_likes,\n",
    "        \n",
    "        # demographic data\n",
    "        author_name = extra_author_attributes.name,\n",
    "        author_birthday = extra_author_attributes.birthdate.date,\n",
    "        author_birthday_resolution = extra_author_attributes.birthdate.resolution,\n",
    "        author_gender = extra_author_attributes.gender,\n",
    "        author_short_name = extra_author_attributes.short_name,\n",
    "        author_url = extra_author_attributes.url,\n",
    "        author_description = extra_author_attributes.description,\n",
    "\n",
    "        # geographic data\n",
    "        \n",
    "        author_continent = extra_author_attributes.world_data.continent,\n",
    "        author_country = extra_author_attributes.world_data.country,\n",
    "        author_country_code = extra_author_attributes.world_data.country_code,\n",
    "        author_region = extra_author_attributes.world_data.region,\n",
    "        author_city = extra_author_attributes.world_data.city,\n",
    "        article_city = extra_article_attributes.world_data.city,\n",
    "        article_latitude = extra_article_attributes.world_data.latitude,\n",
    "        article_longitide = extra_article_attributes.world_data.longitude,\n",
    "        source_continent = extra_source_attributes.world_data.continent,\n",
    "        source_country = extra_source_attributes.world_data.country,\n",
    "        source_country_code = extra_source_attributes.world_data.country_code,\n",
    "        source_region = extra_source_attributes.world_data.region,\n",
    "        source_city = extra_source_attributes.world_data.city\n",
    "    )\n",
    "\n",
    "# filter ot rows based on various criteria\n",
    "\n",
    "noise_category_exclusions <- c(\n",
    "    'real_estate',\n",
    "    'job_offers',\n",
    "    'promotions',\n",
    "    'diet_pharma',\n",
    "    'hate_speech',\n",
    "    'seo_scam'\n",
    ")\n",
    "\n",
    "exclusion_keywords <- read_csv('./data/raw/exclusion_keywords.csv') %>%\n",
    "    pull('keyword') %>%\n",
    "    paste(collapse = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e18c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total raw records: 70970 \n",
      "records after preprocessing: 62654 \n",
      "percent records remaining: 88%"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 10 × 1</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>content</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Food would be nice                                                                                                                                                                                                                        </td></tr>\n",
       "\t<tr><td>RT : And a bit more...#PlantAppreciation Farm fresh veggies!                                                                                                                                                                              </td></tr>\n",
       "\t<tr><td>Homemade pigs in a blanket!!! Hot dog 🌭 in some fresh dough #pigsofinstagram #dinner #snack #food #hotdog #enjoy #yummy #instagood #instafood #quarantinelife #quarentineideasforkids #food #eat #pigsinablanket…                        </td></tr>\n",
       "\t<tr><td><span style=white-space:pre-wrap>oh my fuckin god. ..... this shit is fuckin good as FUCK. shout out to Jamrock Jerk. black owned brand wit BOMB ass food &amp; quality packaging &amp; branding. i love to see it.                                                                </span></td></tr>\n",
       "\t<tr><td>RT : I literally chuckled reading this. These are the kind of folks who eat expired food claiming it's perfectly fine.                                                                                                                    </td></tr>\n",
       "\t<tr><td>Thank you! I'm in awe at their resiliency. We have a food pantry and fresh vegetables give away but students must sign up in advance. Unfortunately that also entails adjusting their schedules just to get food.                         </td></tr>\n",
       "\t<tr><td>RT : Great piece showing what Sixth Street Community Center in the East Village is doing providing free food and fresh vegetables for neighbors. Also spotlights what people in #NYC are going through right now. Thanks and .            </td></tr>\n",
       "\t<tr><td>Don’t hoard TP! It is the older people who are most at risk from the #coronavirus! Go out and shop for them! Buy good stuff like fresh vegetables and greens and tomatoes. Help others!                                                   </td></tr>\n",
       "\t<tr><td>RT : FRESH MEAT FRIDAY: April 16th, 2020 This is what we’ll be listening to today here at the Village HQ. We hope you join us in doing so! #ivoidhanger #Altarofthehornedgod #REPTILIUM #FOES                                             </td></tr>\n",
       "\t<tr><td>RT : So you are saying that the post offices closing, boxes removed, sorting machines that are being trashed &amp; postal employees being fired/told to slow down delivery as well as dead animals, rotten food, missed meds are a conspiracy?</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 10 × 1\n",
       "\\begin{tabular}{l}\n",
       " content\\\\\n",
       " <chr>\\\\\n",
       "\\hline\n",
       "\t Food would be nice                                                                                                                                                                                                                        \\\\\n",
       "\t RT : And a bit more...\\#PlantAppreciation Farm fresh veggies!                                                                                                                                                                              \\\\\n",
       "\t Homemade pigs in a blanket!!! Hot dog 🌭 in some fresh dough \\#pigsofinstagram \\#dinner \\#snack \\#food \\#hotdog \\#enjoy \\#yummy \\#instagood \\#instafood \\#quarantinelife \\#quarentineideasforkids \\#food \\#eat \\#pigsinablanket…                        \\\\\n",
       "\t oh my fuckin god. ..... this shit is fuckin good as FUCK. shout out to Jamrock Jerk. black owned brand wit BOMB ass food \\& quality packaging \\& branding. i love to see it.                                                                \\\\\n",
       "\t RT : I literally chuckled reading this. These are the kind of folks who eat expired food claiming it's perfectly fine.                                                                                                                    \\\\\n",
       "\t Thank you! I'm in awe at their resiliency. We have a food pantry and fresh vegetables give away but students must sign up in advance. Unfortunately that also entails adjusting their schedules just to get food.                         \\\\\n",
       "\t RT : Great piece showing what Sixth Street Community Center in the East Village is doing providing free food and fresh vegetables for neighbors. Also spotlights what people in \\#NYC are going through right now. Thanks and .            \\\\\n",
       "\t Don’t hoard TP! It is the older people who are most at risk from the \\#coronavirus! Go out and shop for them! Buy good stuff like fresh vegetables and greens and tomatoes. Help others!                                                   \\\\\n",
       "\t RT : FRESH MEAT FRIDAY: April 16th, 2020 This is what we’ll be listening to today here at the Village HQ. We hope you join us in doing so! \\#ivoidhanger \\#Altarofthehornedgod \\#REPTILIUM \\#FOES                                             \\\\\n",
       "\t RT : So you are saying that the post offices closing, boxes removed, sorting machines that are being trashed \\& postal employees being fired/told to slow down delivery as well as dead animals, rotten food, missed meds are a conspiracy?\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 10 × 1\n",
       "\n",
       "| content &lt;chr&gt; |\n",
       "|---|\n",
       "| Food would be nice                                                                                                                                                                                                                         |\n",
       "| RT : And a bit more...#PlantAppreciation Farm fresh veggies!                                                                                                                                                                               |\n",
       "| Homemade pigs in a blanket!!! Hot dog 🌭 in some fresh dough #pigsofinstagram #dinner #snack #food #hotdog #enjoy #yummy #instagood #instafood #quarantinelife #quarentineideasforkids #food #eat #pigsinablanket…                         |\n",
       "| oh my fuckin god. ..... this shit is fuckin good as FUCK. shout out to Jamrock Jerk. black owned brand wit BOMB ass food &amp; quality packaging &amp; branding. i love to see it.                                                                 |\n",
       "| RT : I literally chuckled reading this. These are the kind of folks who eat expired food claiming it's perfectly fine.                                                                                                                     |\n",
       "| Thank you! I'm in awe at their resiliency. We have a food pantry and fresh vegetables give away but students must sign up in advance. Unfortunately that also entails adjusting their schedules just to get food.                          |\n",
       "| RT : Great piece showing what Sixth Street Community Center in the East Village is doing providing free food and fresh vegetables for neighbors. Also spotlights what people in #NYC are going through right now. Thanks and .             |\n",
       "| Don’t hoard TP! It is the older people who are most at risk from the #coronavirus! Go out and shop for them! Buy good stuff like fresh vegetables and greens and tomatoes. Help others!                                                    |\n",
       "| RT : FRESH MEAT FRIDAY: April 16th, 2020 This is what we’ll be listening to today here at the Village HQ. We hope you join us in doing so! #ivoidhanger #Altarofthehornedgod #REPTILIUM #FOES                                              |\n",
       "| RT : So you are saying that the post offices closing, boxes removed, sorting machines that are being trashed &amp; postal employees being fired/told to slow down delivery as well as dead animals, rotten food, missed meds are a conspiracy? |\n",
       "\n"
      ],
      "text/plain": [
       "   content                                                                                                                                                                                                                                   \n",
       "1  Food would be nice                                                                                                                                                                                                                        \n",
       "2  RT : And a bit more...#PlantAppreciation Farm fresh veggies!                                                                                                                                                                              \n",
       "3  Homemade pigs in a blanket!!! Hot dog 🌭 in some fresh dough #pigsofinstagram #dinner #snack #food #hotdog #enjoy #yummy #instagood #instafood #quarantinelife #quarentineideasforkids #food #eat #pigsinablanket…                        \n",
       "4  oh my fuckin god. ..... this shit is fuckin good as FUCK. shout out to Jamrock Jerk. black owned brand wit BOMB ass food & quality packaging & branding. i love to see it.                                                                \n",
       "5  RT : I literally chuckled reading this. These are the kind of folks who eat expired food claiming it's perfectly fine.                                                                                                                    \n",
       "6  Thank you! I'm in awe at their resiliency. We have a food pantry and fresh vegetables give away but students must sign up in advance. Unfortunately that also entails adjusting their schedules just to get food.                         \n",
       "7  RT : Great piece showing what Sixth Street Community Center in the East Village is doing providing free food and fresh vegetables for neighbors. Also spotlights what people in #NYC are going through right now. Thanks and .            \n",
       "8  Don’t hoard TP! It is the older people who are most at risk from the #coronavirus! Go out and shop for them! Buy good stuff like fresh vegetables and greens and tomatoes. Help others!                                                   \n",
       "9  RT : FRESH MEAT FRIDAY: April 16th, 2020 This is what we’ll be listening to today here at the Village HQ. We hope you join us in doing so! #ivoidhanger #Altarofthehornedgod #REPTILIUM #FOES                                             \n",
       "10 RT : So you are saying that the post offices closing, boxes removed, sorting machines that are being trashed & postal employees being fired/told to slow down delivery as well as dead animals, rotten food, missed meds are a conspiracy?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "# run this block EVERY TIME you add new exclusion keywords\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "\n",
    "exclusion_keywords <- paste0(\n",
    "    exclusion_keywords,\n",
    "    '|',\n",
    "    paste(list(\n",
    "        #################################################\n",
    "        #################################################\n",
    "        # insert keywords in the orange area below here\n",
    "        # only edit below this line\n",
    "        # make sure last item is NOT followed by comma\n",
    "        # one keyword per line\n",
    "        # put a comma after each keyword except the last one\n",
    "        #################################################\n",
    "        #################################################\n",
    "        \"Perry, Iowa\",\n",
    "        \"Evolution Gaming\",\n",
    "        \"Detroit\",\n",
    "        \"Zimbabwe and NL\",\n",
    "        \"Dr Gleicher\",\n",
    "\"Quality cocktails\",\n",
    "        \"Ecosense Lighting\",\n",
    "        \"NORTH MELBOURNE\",\n",
    "\"Professional video shoot\",\n",
    "        \"Bob Chepak\",\n",
    "        \"HIGHFALUTIN\",\n",
    "        \"global maltitol\",\n",
    "        \"Campo dei Fiori\",\n",
    "        \"Westport, Conn\",\n",
    "        \"IBL Studios\",\n",
    "\"Census Bureau\",\n",
    "        \"Prosseco\",\n",
    "\"Taiwan\",        \n",
    "\"#FWSells\",\n",
    "\"$FDP\",\n",
    "\"#SaveEboforest\",\n",
    "        \"Philly\",\n",
    "\"Cachaca\",\n",
    "\"@scentlodge\",\n",
    "        \"onlyfans.com\",\n",
    "        \"cassowary\"\n",
    "        #################################################\n",
    "        #################################################\n",
    "        # no more edits below this line\n",
    "        #################################################\n",
    "        #################################################\n",
    "    ), collapse = '|')\n",
    ")\n",
    "\n",
    "data.filtered <- data.preprocessed %>%\n",
    "    mutate(\n",
    "        content = str_remove_all(content, pattern = '@\\\\w+') %>% rm_url()\n",
    "    ) %>%\n",
    "    filter(\n",
    "        !is.na(content),\n",
    "        length(content) > 15,\n",
    "        porn_level == 0,\n",
    "        lang == 'en',\n",
    "        !noise_category %in% noise_category_exclusions,\n",
    "        !grepl(exclusion_keywords, content),\n",
    "        !grepl('\\\\$SNAP', content)\n",
    "    )\n",
    "\n",
    "total_records_raw <- data %>% nrow()\n",
    "total_records_filtered <- data.filtered %>% nrow()\n",
    "\n",
    "cat(paste('total raw records:', total_records_raw, '\\n'))\n",
    "cat(paste('records after preprocessing:', total_records_filtered, '\\n'))\n",
    "cat(paste('percent records remaining:', percent(total_records_filtered / total_records_raw)))\n",
    "\n",
    "set.seed(\n",
    "    ############################\n",
    "    ############################\n",
    "    # change the following seed number to get a different random sample\n",
    "    # you can use any number\n",
    "    # run this until you get an average of 90% precision over 5 runs\n",
    "    ############################\n",
    "    ############################\n",
    "    2032\n",
    "    ############################\n",
    "    ############################\n",
    "    # no more edits below this line\n",
    "    ############################\n",
    "    ############################\n",
    ")\n",
    "\n",
    "data.filtered %>% distinct(content) %>% sample_n(10) %>% select(content)\n",
    "data.filtered %>% write_csv('./data/generated/filtered_food_quality.csv');\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "# read the random sample below\n",
    "# calculate your own precision accuracy\n",
    "# if you want to add more exclusion keywords, go back to the top of this cell, edit it, and run it again\n",
    "#     you will AUTOMATICALLY get a different random sample of 10\n",
    "# if you want a different sample to check for precision AND do not want to add to the exclusion keywords,\n",
    "# change the seed number above and run this cell again\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "#######################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
